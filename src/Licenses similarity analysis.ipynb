{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Government licenses analysis\n",
    "\n",
    "In this notebook, we'll analyse a list of licenses gathered from government websites, comparing them among each other and with known licenses. We want to find out:\n",
    "\n",
    "* Which licenses are standard (i.e. not custom)\n",
    "* Are there licenses very similar, indicating they came from the same place?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/vitor/Projetos/okfn/licenses_analysis/src/../data/gov_licenses.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-8f273abf714e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlicenses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mlicenses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLICENSES_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mknown_licenses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_known_licenses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKNOWN_LICENSES_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-106-8f273abf714e>\u001b[0m in \u001b[0;36mload_csv\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/vitor/Projetos/okfn/licenses_analysis/src/../data/gov_licenses.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import csv\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_PATH = os.path.join(os.getcwd(), '..', 'data')\n",
    "LICENSES_PATH = os.path.join(DATA_PATH, 'gov_licenses.csv')\n",
    "KNOWN_LICENSES_PATH = os.path.join(DATA_PATH, 'licenses', '*.txt')\n",
    "LICENSE_TEXT_COL = 'License text (original)'\n",
    "\n",
    "def load_csv(path):\n",
    "    with open(path, 'r') as fp:\n",
    "        reader = csv.DictReader(fp)\n",
    "        return [row for row in reader]\n",
    "    \n",
    "def load_known_licenses(path):\n",
    "    def _load_license(text):\n",
    "        matches = re.split(r'[^-]---\\w*\\n', text)\n",
    "\n",
    "        if not matches:\n",
    "            return\n",
    "\n",
    "        assert len(matches) == 2, 'Wrong matches'\n",
    "        metadata, text = matches\n",
    "\n",
    "        license = yaml.load(metadata)\n",
    "        license['text'] = text.strip()\n",
    "\n",
    "        return license\n",
    "\n",
    "    licenses = []\n",
    "\n",
    "    for filepath in glob.iglob(path):\n",
    "        _, filename = os.path.split(filepath)\n",
    "        text = open(filepath, 'r').read()\n",
    "        licenses.append(_load_license(text))\n",
    "\n",
    "    return licenses\n",
    "\n",
    "licenses = load_csv(LICENSES_PATH)\n",
    "known_licenses = load_known_licenses(KNOWN_LICENSES_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for comparisons\n",
    "\n",
    "Here we clean and prepare the licenses' data to detect similarities among them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def get_min_distances(distances, is_pairwise=False):\n",
    "    result = []\n",
    "    \n",
    "    for index, distance in enumerate(distances):\n",
    "        mask = np.full(len(distance), True)\n",
    "        \n",
    "        if is_pairwise:\n",
    "            # Remove the current distance from the list of possibilities\n",
    "            # otherwise we'll always find out that the closest point is itself\n",
    "            # (distance == 0)\n",
    "            np.put(mask, index, False)\n",
    "            \n",
    "        min_distance = distance[mask].min()\n",
    "\n",
    "        result.append({\n",
    "            'index': index,\n",
    "            'distance': min_distance,\n",
    "            'min_indexes': np.where(distance == min_distance)[0],\n",
    "        })\n",
    "\n",
    "    return result\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(stop_words='english', norm='l2', sublinear_tf=True)\n",
    ")\n",
    "\n",
    "gov_licenses_data = [\n",
    "    {'index': index, 'type': 'gov', 'text': license[LICENSE_TEXT_COL]}\n",
    "    for index, license in enumerate(licenses)\n",
    "]\n",
    "\n",
    "known_licenses_data = [\n",
    "    {'index': index, 'type': 'known', 'text': license['text']}\n",
    "    for index, license in enumerate(known_licenses)\n",
    "]\n",
    "\n",
    "prepared_data = np.array(gov_licenses_data + known_licenses_data)\n",
    "\n",
    "# We need this to create the masks (there's certainly a better way, but I don't know)\n",
    "prepared_data_types = np.array([data['type'] for data in prepared_data])\n",
    "gov_mask = prepared_data_types == 'gov'\n",
    "known_licenses_mask = prepared_data_types == 'known'\n",
    "\n",
    "X = pipeline.fit_transform([\n",
    "    data['text'] for data in prepared_data\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare government's licenses to known licenses\n",
    "\n",
    "We're trying to determine how similar the government licenses are to a few known licenses. Them being similar can mean they're using the same license (changing things like year of copyrigh holder names), or that they were based in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_df(min_distances, X, y):\n",
    "    ROW_OFFSET = 2  # 1 for the header, and 1 because it starts in 1, not 0 like lists\n",
    "    pairs_seen = set()\n",
    "    result = []\n",
    "    for potential in sorted(min_distances, key=lambda x: x['distance']):\n",
    "        index = potential['index']\n",
    "        min_index = potential['min_indexes'][0]\n",
    "        pair = ','.join(sorted((str(index), str(min_index))))\n",
    "        \n",
    "        if pair in pairs_seen:\n",
    "            continue\n",
    "            \n",
    "        pairs_seen.add(pair)\n",
    "\n",
    "        data = {\n",
    "            'distance': potential['distance'],\n",
    "            'row': index + ROW_OFFSET,\n",
    "            'license_text': X[index][LICENSE_TEXT_COL],\n",
    "            'closest_match': y[min_index]['title'],\n",
    "        }\n",
    "        result.append(data)\n",
    "\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "distances_to_known_licenses = sklearn.metrics.pairwise.pairwise_distances(\n",
    "    X[gov_mask].todense(),\n",
    "    X[known_licenses_mask].todense(),\n",
    "    metric='dice'\n",
    ")\n",
    "\n",
    "min_distances = get_min_distances(distances_to_known_licenses)\n",
    "\n",
    "plt.hist([d['distance'] for d in min_distances])\n",
    "plt.title(\"Distribution of distances between government and known licenses\")\n",
    "plt.show()\n",
    "\n",
    "display(generate_df(min_distances, licenses, known_licenses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing government licenses among themselves\n",
    "\n",
    "We're comparing every pair of government licenses, and selecting the closest matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_df(min_distances):\n",
    "    pairs_seen = set()\n",
    "    result = []\n",
    "    for potential in sorted(min_distances, key=lambda x: x['distance']):\n",
    "        index = potential['index']\n",
    "        min_index = potential['min_indexes'][0]\n",
    "        pair = ','.join(sorted((str(index), str(min_index))))\n",
    "        \n",
    "        if pair in pairs_seen:\n",
    "            continue\n",
    "            \n",
    "        pairs_seen.add(pair)\n",
    "        \n",
    "        data = {\n",
    "            'distance': potential['distance'],\n",
    "            'license_1.row': index + 2,\n",
    "            'license_2.row': min_index + 2,\n",
    "            'license_1': licenses[index][LICENSE_TEXT_COL],\n",
    "            'license_2': licenses[min_index][LICENSE_TEXT_COL],\n",
    "        }\n",
    "        result.append(data)\n",
    "\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "distances_among_themselves = sklearn.metrics.pairwise.pairwise_distances(\n",
    "    X[gov_mask].todense(),\n",
    "    metric='dice'\n",
    ")\n",
    "\n",
    "min_distances = get_min_distances(distances_among_themselves, is_pairwise=True)\n",
    "plt.hist([d['distance'] for d in min_distances])\n",
    "plt.title(\"Distribution of the licenses texts to their most similar ones\")\n",
    "plt.show()\n",
    "\n",
    "display(generate_df(min_distances))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
